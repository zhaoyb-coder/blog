---
title: Redis-概述
date: 2024-01-03 18:44:16
permalink: /data/932202/
categories:
  - Redis
tags:
  - Redis
author: 
  name: zhaoyb
  link: https://github.com/zhaoyb-coder
---

# Redis-概述

### 1、数据结构

![image-20240103162410843](https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20240103162410843.png)

#### 1.1、String

> 字符串对象的编码可以是int、raw或者embstr

+ 如果保存的是整数，并且整数可以被long表示，那么底层存储的字符串编码就是int

  ```shell
  # 设置num值为100
  > set num 100
  OK
  # 查看num编码
  > OBJECT ENCODING num
  "int"
  ```

+ 如果保存的是字符串，小于等于32字节，那么字符串对象编码使用embstr来保存

  ```shell
  > set msg "hello"
  OK
  > OBJECT ENCODING msg
  "embstr"
  ```

+ 如果保存的是字符串，大于32字节，那么字符串使用简单动态字符串（SDS）来保存，编码设置为raw

  ```shell
  > set bigmsg "long long ago......."
  OK
  # 查询字符串大小
  > STRLEN bigmsg
  (integer)40
  > OBJECT ENCODING bigmsg
  "raw"
  ```

#### 1.2、List

> 列表对象的编码可以是ziplist或者linkedlist

+ 列表对象保存的所有字符串元素的长度都小于64字节 并且 列表对象保存的元素数量小于512个，使用ziplist编码

  ```shell
  # 所有元素的长度都小于64字节
  > RPUSH blah "hello" "world" "again"
  (integer)3
  > OBJECT ENCODING blah
  "ziplist"
  #将一个65字节长的元素推入列表对象中
  > RPUSH blah "wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww"
  (integer) 4
  #编码已改变
  > OBJECT ENCODING blah
  "linkedlist"
  ```

+ 否则 使用linkedlist编码

  ```shell
  # 列表对象包含512个元素
  > EVAL "for i=1, 512 do redis.call('RPUSH', KEYS[1],i)end" 1 "integers"
  (nil)
  > LLEN integers
  (integer) 512
  > OBJECT ENCODING integers
  "ziplist"
  # 再向列表对象推入一个新元素，使得对象保存的元素数量达到513个
  > RPUSH integers 513
  (integer) 513
  # 编码已改变
  > OBJECT ENCODING integers
  "linkedlist"
  ```

#### 1.3、Hash

> 哈希对象的编码可以是ziplist或者hashtable

+ 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节 并且 哈希对象保存的键值对数量小于512个，哈希对象使用ziplist编码

  ```shell
  # 哈希对象只包含一个键和值都不超过64个字节的键值对
  > HSET book name "Mastering C++ in 21 days"
  (integer) 1
  > OBJECT ENCODING book
  "ziplist"
  # 向哈希对象添加一个新的键值对，键的长度为66字节
  > HSET book long_long_long_long_long_long_long_long_long_long_long_description "content"
  (integer) 1
  # 编码已改变
  > OBJECT ENCODING book
  "hashtable"
  ```

+  否则 使用hashtable编码

  ```shell
  # 创建一个包含512个键值对的哈希对象
  > EVAL "for i=1, 512 do redis.call('HSET', KEYS[1], i, i)end" 1 "numbers"
  (nil)
  > HLEN numbers
  (integer) 512
  > OBJECT ENCODING numbers
  "ziplist"
  # 再向哈希对象添加一个新的键值对，使得键值对的数量变成513个
  > HMSET numbers "key" "value"
  OK
  > HLEN numbers
  (integer) 513
  # 编码改变
  > OBJECT ENCODING numbers
  "hashtable"
  ```

#### 1.4、Set

> 集合对象的编码可以是intset或者hashtable

+ 集合对象保存的所有元素都是整数值 并且 集合对象保存的元素数量不超过512个，使用intset编码

  ```shell
  > SADD numbers 1 3 5
  (integer) 3
  > OBJECT ENCODING numbers
  "intset"
  ```

+ 否则使用hashtable编码

  ```shell
  > SADD numbers "seven"
  (integer) 1
  > OBJECT ENCODING numbers
  "hashtable"
  ```

#### 1.5、ZSet

> 有序集合的编码可以是ziplist或者skiplist

+ 有序集合保存的元素数量小于128个 并且 有序集合保存的所有元素成员的长度都小于64字节，使用ziplist编码

  ```shell
  # 对象包含了128个元素
  > EVAL "for i=1, 128 do redis.call('ZADD', KEYS[1], i, i) end" 1 numbers
  (nil)
  > ZCARD numbers
  (integer) 128
  > OBJECT ENCODING numbers
  "ziplist"
  # 再添加一个新元素
  > ZADD numbers 3.14 pi
  (integer) 1
  # 对象包含的元素数量变为129个
  > ZCARD numbers
  (integer) 129
  # 编码已改变
  > OBJECT ENCODING numbers
  "skiplist"
  ```

+ 否则使用skiplist编码

  ```shell
  # 向有序集合添加一个成员只有三字节长的元素
  > ZADD blah 1.0 www
  (integer) 1
  > OBJECT ENCODING blah
  "ziplist"
  # 向有序集合添加一个成员为66字节长的元素
  > ZADD blah 2.0 ooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo
  (integer) 1
  # 编码已改变
  > OBJECT ENCODING blah
  "skiplist"
  ```

### 2、过期键删除策略

如果一个键过期了，那么它什么时候会被删除呢？

+ **定时删除**：在设置键的过期时间的同时，创建一个定时器（timer），让定时器在键的过期时间来临时，立即执行对键的删除操作
  内存友好，CPU不友好，在过期键比较多的情况下，删除过期键这一行为可能会占用相当一部分CPU时间，在内存不紧张但是CPU时间非常紧张的情况下，将CPU时间用在删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响
+ **惰性删除**：放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键
  内存不友好，CPU友好，如果一个键已经过期，而这个键又仍然保留在数据库中，那么只要这个过期键不被删除，它所占用的内存就不会释放，可以理解为一种内存泄漏
+ **定期删除**：每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定；定期删除策略是前两种策略的一种整合和折中
  + 定期删除策略每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响
  + 通过定期删除过期键，定期删除策略有效地减少了因为过期键而带来的内存浪费

Redis使用的是惰性删除和定期删除两种策略：通过配合使用这两种删除策略，服务器可以很好地在合理使用CPU时间和避免浪费内存空间之间取得平衡。

![image-20240104160325217](https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20240104160325217.png)

过期键的定期删除策略由redis.c/activeExpireCycle函数实现：

+ 函数每次运行时，都从一定数量的数据库中取出一定数量的随机键进行检查，并删除其中的过期键
+ 全局变量current_db会记录当前activeExpireCycle函数检查的进度，并在下一次activeExpireCycle函数调用时，接着上一次的进度进行处理。比如说，如果当前activeExpireCycle函数在遍历10号数据库时返回了，那么下次activeExpireCycle函数执行时，将从11号数据库开始查找并删除过期键
+ 随着activeExpireCycle函数的不断执行，服务器中的所有数据库都会被检查一遍，这时函数将current_db变量重置为0，然后再次开始新一轮的检查工作

### 3、AOF、RDB对于过期键的影响

#### 3.1、RDB

生成RDB文件对于过期键的影响：

在执行SAVE命令或者BGSAVE命令创建一个新的RDB文件时，程序会对数据库中的键进行检查，已过期的键不会被保存到新创建的RDB文件中

------

载入RDB文件对于过期键的影响：

+ 如果是主服务器：在载入RDB文件时，程序会对文件中保存的键进行检查，未过期的键会被载入到数据库中，而过期键则会被忽略。
+ 如果是从服务器：在载入RDB文件时，文件中保存的所有键，不论是否过期，都会被载入到数据库中。不过，因为主从服务器在进行数据同步的时候，从服务器的数据库就会被清空。

#### 3.2、AOF

当服务器以AOF持久化模式运行时，如果数据库中的某个键已经过期，但它还没有被惰性删除或者定期删除，那么AOF文件不会因为这个过期键而产生任何影响

当过期键被惰性删除或者定期删除之后，程序会向AOF文件追加（append）一条DEL命令，来显式地记录该键已被删除

------

AOF重写过程：

在执行AOF重写的过程中，程序会对数据库中的键进行检查，已过期的键不会被保存到重写后的AOF文件中

------

集群复制：

+ 主服务器在删除一个过期键之后，会显式地向所有从服务器发送一个DEL命令，告知从服务器删除这个过期键
+ 从服务器在执行客户端发送的读命令时，即使碰到过期键也不会将过期键删除，而是继续像处理未过期的键一样来处理过期键（`从服务器对于过期键也会返回给客户端`）
+ 从服务器只有在接到主服务器发来的DEL命令之后，才会删除过期键

### 4、Redis持久化

#### 4.1、RDB

RDB文件的生成：

有两个Redis命令可以用于生成RDB文件，一个是SAVE，另一个是BGSAVE

+ SAVE命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止

+ BGSAVE命令会派生出一个子进程，然后由子进程负责创建RDB文件，服务器进程（父进程）继续处理命令请求

自动BGSAVE:

```shell
save 900 1
save 300 10
save 60 10000
```

------

RDB文件的载入：

RDB文件的载入工作是在服务器启动时自动执行的，只要Redis服务器在启动时检测到RDB文件存在，它就会自动载入RDB文件。（因为AOF文件的更新频率通常比RDB更频繁，所以如果服务器同时开启了AOF持久化，那么服务器会优先使用AOF文件来还原数据库状态）

服务器在载入RDB文件期间，会一直处于阻塞状态，直到载入工作完成为止

#### 4.2、AOF

> AOF持久化是通过保存Redis服务器所执行的写命令来记录数据库状态的

![image-20240105153144987](https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20240105153144987.png)

**AOF持久化**功能的实现可以分为命令追加（append）、文件写入、文件同步（sync）三个步骤

+ **命令追加**：当AOF持久化功能处于打开状态时，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾
+ **文件写入**：服务器在处理文件事件时可能会执行写命令，使得一些内容被追加到aof_buf缓冲区里面，所以在服务器每次结束一个事件循环之前，它都会调用flushAppendOnlyFile函数
+ **文件同步**：flushAppendOnlyFile函数，考虑是否需要将aof_buf缓冲区中的内容写入和保存到AOF文件里面(系统调用的fsync函数，会把内存缓冲区的数据刷入磁盘)。flushAppendOnlyFile函数的行为由服务器配置的appendfsync选项的值来决定，`默认everysec`
  ![image-20240105154613406](https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20240105154613406.png)

------

**AOF重写**：随着服务器运行时间的流逝，AOF文件中的内容会越来越多，文件的体积也会越来越大

为了解决AOF文件体积膨胀的问题，Redis提供了AOF文件重写（rewrite）功能。通过该功能，Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，新旧两个AOF文件所保存的数据库状态相同，但新AOF文件不会包含任何浪费空间的冗余命令，所以新AOF文件的体积通常会比旧AOF文件的体积要小得多

**AOF文件重写并不需要对现有的AOF文件进行任何读取、分析或者写入操作，这个功能是通过读取服务器当前的数据库状态来实现的**

AOF重写的实现：

使用子进程进行数据重写，避免主进程阻塞，但是这样会出现主进程依旧在进行数据存储，和子进程数据不一致的情况，那么如何处理？

AOF重写缓冲区：

为了解决这种不一致问题，Redis设置了AOF重写缓冲区，这个缓冲区在服务器创建子进程之后开始使用，也就是说当创建子进程之后，Redis主进程接收到一个客户端命令之后会进行三步操作

1、执行客户端命令

2、把执行后的命令写入AOF缓冲区

3、把执行的后的命令写入AOF重写缓冲区

这样能保证什么呢？首先能保证AOF缓冲区拥有最新的内容，也就是说现有的AOF文件数据都是最新的，然后重写缓冲区能存储从创建子进程开始之后的所有的命令。然后子进程重写AOF完成之后，会给主进程发送一个信号量，主进程接收之后，开始进入阻塞状态（不接受任何客户端命令），然后主进程做了两件事：一个是将AOF重写缓冲区的数据都加入到新的AOF文件中，这就保证了新的AOF文件内容和原有AOF保持一致，第二是对新的AOF文件进行改名，并原子的把旧AOF进行覆盖，完成新旧AOF文件的替换

![image-20240105162959171](https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20240105162959171.png)

